{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Ckvl4YVRsL",
        "outputId": "0862d899-5fef-4f37-9071-d9108ac0fe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "4oFgWoIUVZTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data from the file\n",
        "file_path = 'tasks_all.json'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Convert JSON data to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save dataframe as csv\n",
        "# df.to_csv('tasks.csv', index=False)"
      ],
      "metadata": {
        "id": "VXbg-xZaVcwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'column_name' is the column you want to check\n",
        "categories = 'category' # Replace 'priority' with your actual column name\n",
        "unique_values_cat = df[categories].unique()\n",
        "modalities = 'modality' # Replace 'priority' with your actual column name\n",
        "unique_values_mod = df[modalities].unique()\n",
        "print(unique_values_cat)\n",
        "print(unique_values_mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ-BeFstWSEW",
        "outputId": "82306d6d-df4a-4508-da5a-3f919e147a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['transcription' 'captioning' 'summarization' 'translation'\n",
            " 'text generation' 'sentiment analysis' 'question answering'\n",
            " 'content moderation' 'content enhancement' 'speech recognition'\n",
            " 'visual description' 'content analysis' 'voice generation']\n",
            "['audio' 'video' 'text' 'image']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reload the CSV file\n",
        "tasks_csv_path = '/mnt/data/tasks.csv'\n",
        "tasks_df = pd.read_csv(tasks_csv_path)\n",
        "\n",
        "# Add necessary columns for the models\n",
        "models = [\"gpt4\", \"gpt3.5\", \"claude2\", \"mistral_7b\", \"mistral_8x7b\"]\n",
        "columns = [\"latency\", \"price\", \"human_win_rate\", \"judge_win_rate\"]\n",
        "\n",
        "# Add columns for each model\n",
        "for model in models:\n",
        "    for col in columns:\n",
        "        tasks_df[f\"{model}_{col}\"] = np.nan\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Fill the DataFrame based on the instructions\n",
        "for index, row in tasks_df.iterrows():\n",
        "    task_type = row[\"task_type\"].lower()  # Task type determines weights\n",
        "    modality = row[\"modality\"].lower()  # Text, audio, video, image\n",
        "\n",
        "    for model in models:\n",
        "        # Assign latency values\n",
        "        if model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "            latency = np.random.uniform(0.5, 3)  # Lower latency models\n",
        "        else:\n",
        "            latency = np.random.uniform(3, 10)  # Higher latency models\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            latency *= 1.5  # Add weight for non-text modalities\n",
        "        tasks_df.loc[index, f\"{model}_latency\"] = latency\n",
        "\n",
        "        # Assign price values\n",
        "        if model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "            price = np.random.uniform(0.05, 0.2)  # Lower cost models\n",
        "        else:\n",
        "            price = np.random.uniform(0.5, 2)  # Higher cost models\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            price *= 2  # Add weight for non-text modalities\n",
        "        tasks_df.loc[index, f\"{model}_price\"] = price\n",
        "\n",
        "        # Assign human win rate and judge win rate\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            if model == \"gpt4\":\n",
        "                human_win_rate = np.random.uniform(0.7, 1)\n",
        "                judge_win_rate = np.random.uniform(0.7, 1)\n",
        "            else:\n",
        "                human_win_rate = np.random.choice([0, np.random.uniform(0, 0.3)], p=[0.8, 0.2])\n",
        "                judge_win_rate = np.random.choice([0, np.random.uniform(0, 0.3)], p=[0.8, 0.2])\n",
        "        else:\n",
        "            if model == \"gpt4\":\n",
        "                human_win_rate = np.random.uniform(0.7, 1)\n",
        "                judge_win_rate = np.random.uniform(0.7, 1)\n",
        "            elif model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "                human_win_rate = np.random.uniform(0.3, 0.6)\n",
        "                judge_win_rate = np.random.uniform(0.3, 0.6)\n",
        "            else:\n",
        "                human_win_rate = np.random.uniform(0.4, 0.7)\n",
        "                judge_win_rate = np.random.uniform(0.4, 0.7)\n",
        "\n",
        "        tasks_df.loc[index, f\"{model}_human_win_rate\"] = human_win_rate\n",
        "        tasks_df.loc[index, f\"{model}_judge_win_rate\"] = judge_win_rate\n",
        "\n",
        "# Export the updated DataFrame to a CSV file\n",
        "output_csv_path = '/mnt/data/updated_tasks.csv'\n",
        "tasks_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "output_csv_path\n"
      ],
      "metadata": {
        "id": "Ng1WcQwsuvgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reloading the data again to process with correct logic\n",
        "tasks_df = pd.read_csv(tasks_csv_path)\n",
        "\n",
        "# Add missing columns for additional models if needed\n",
        "models = [\"gpt4\", \"gpt3.5\", \"claude2\", \"mistral_7b\", \"mistral_8x7b\"]\n",
        "columns = [\"latency\", \"price\", \"human_win_rate\", \"judge_win_rate\"]\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Process the data to fill in the missing columns based on instructions\n",
        "for index, row in tasks_df.iterrows():\n",
        "    modality = row[\"modality\"].lower()  # Determine task modality (audio, video, text, image)\n",
        "    category = row[\"category\"].lower()  # Task type like transcription, summarization\n",
        "\n",
        "    for model in models:\n",
        "        # Assign latency values\n",
        "        if model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "            latency = np.random.uniform(0.5, 3)  # Lower latency models\n",
        "        else:\n",
        "            latency = np.random.uniform(3, 10)  # Higher latency models\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            latency *= 1.5  # Add weight for non-text modalities\n",
        "        tasks_df.loc[index, f\"{model}_latency\"] = latency\n",
        "\n",
        "        # Assign price values\n",
        "        if model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "            price = np.random.uniform(0.05, 0.2)  # Lower cost models\n",
        "        else:\n",
        "            price = np.random.uniform(0.5, 2)  # Higher cost models\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            price *= 2  # Add weight for non-text modalities\n",
        "        tasks_df.loc[index, f\"{model}_price\"] = price\n",
        "\n",
        "        # Assign human win rate and judge win rate\n",
        "        if modality in [\"audio\", \"video\", \"image\"]:\n",
        "            if model == \"gpt4\":\n",
        "                human_win_rate = np.random.uniform(0.7, 1)\n",
        "                judge_win_rate = np.random.uniform(0.7, 1)\n",
        "            else:\n",
        "                human_win_rate = np.random.choice([0, np.random.uniform(0, 0.3)], p=[0.8, 0.2])\n",
        "                judge_win_rate = np.random.choice([0, np.random.uniform(0, 0.3)], p=[0.8, 0.2])\n",
        "        else:\n",
        "            if model == \"gpt4\":\n",
        "                human_win_rate = np.random.uniform(0.7, 1)\n",
        "                judge_win_rate = np.random.uniform(0.7, 1)\n",
        "            elif model in [\"mistral_7b\", \"mistral_8x7b\", \"gpt3.5\"]:\n",
        "                human_win_rate = np.random.uniform(0.3, 0.6)\n",
        "                judge_win_rate = np.random.uniform(0.3, 0.6)\n",
        "            else:\n",
        "                human_win_rate = np.random.uniform(0.4, 0.7)\n",
        "                judge_win_rate = np.random.uniform(0.4, 0.7)\n",
        "\n",
        "        tasks_df.loc[index, f\"{model}_human_win_rate\"] = human_win_rate\n",
        "        tasks_df.loc[index, f\"{model}_judge_win_rate\"] = judge_win_rate\n",
        "\n",
        "# Export the updated DataFrame to a CSV file\n",
        "output_csv_path = '/mnt/data/updated_tasks.csv'\n",
        "tasks_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "output_csv_path\n"
      ],
      "metadata": {
        "id": "K_f_lQs-XGuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reload the updated CSV file\n",
        "updated_tasks_csv_path = '/mnt/data/updated_tasks.csv'\n",
        "updated_tasks_df = pd.read_csv(updated_tasks_csv_path)\n",
        "\n",
        "# Calculate averages for each category without losing modalities\n",
        "averages_df = updated_tasks_df.groupby(['modality', 'category']).mean().reset_index()\n",
        "\n",
        "# Display the resulting DataFrame to the user\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Average Values by Modality and Category\", dataframe=averages_df)\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "averages_output_path = '/mnt/data/averages_by_modality_and_category.csv'\n",
        "averages_df.to_csv(averages_output_path, index=False)\n",
        "\n",
        "averages_output_path\n"
      ],
      "metadata": {
        "id": "dU6WuJmNB5iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the averages CSV file\n",
        "averages_file = 'averages_by_modality_and_category.csv'  # Replace with your file path\n",
        "averages_df = pd.read_csv(averages_file)\n",
        "\n",
        "# Available models\n",
        "models = [\n",
        "    \"anthropic/claude-2\",\n",
        "    \"openai/gpt-3.5-turbo-1106\",\n",
        "    \"openai/gpt-4-1106-preview\",\n",
        "    \"mistralai/mistral-7b-instruct\",\n",
        "    \"mistralai/mixtral-8x7b-instruct\"\n",
        "]\n",
        "\n",
        "# Get user input\n",
        "def get_user_input():\n",
        "    print(\"Available modalities:\", averages_df['modality'].unique())\n",
        "    modality = input(\"Enter the modality: \").lower()\n",
        "\n",
        "    print(\"Available categories:\", averages_df['category'].unique())\n",
        "    category = input(\"Enter the category: \").lower()\n",
        "\n",
        "    prompt = input(\"Enter your prompt: \")\n",
        "\n",
        "    preferred_latency = float(input(\"Enter your preferred maximum latency (e.g., 5): \"))\n",
        "    preferred_price = float(input(\"Enter your preferred maximum price (e.g., 1.5): \"))\n",
        "    preferred_accuracy = float(input(\"Enter your preferred minimum accuracy (e.g., 0.6): \"))\n",
        "\n",
        "    return modality, category, prompt, preferred_latency, preferred_price, preferred_accuracy\n",
        "\n",
        "# Suggest the best model\n",
        "def suggest_best_model(modality, category, preferred_latency, preferred_price, preferred_accuracy):\n",
        "    # Filter the data for the specified modality and category\n",
        "    filtered_df = averages_df[(averages_df['modality'] == modality) & (averages_df['category'] == category)]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return \"No data available for the specified modality and category.\"\n",
        "\n",
        "    # Add a ranking column based on priority: price, latency, and accuracy\n",
        "    for model in models:\n",
        "        filtered_df[f'{model}_score'] = (\n",
        "            (filtered_df[f'{model}:price'] <= preferred_price).astype(int) +\n",
        "            (filtered_df[f'{model}:latency'] <= preferred_latency).astype(int) +\n",
        "            (filtered_df[f'{model}:human_win_rate'] >= preferred_accuracy).astype(int) +\n",
        "            (filtered_df[f'{model}:judge_win_rate'] >= preferred_accuracy).astype(int)\n",
        "        )\n",
        "\n",
        "    # Find the best model based on the highest score\n",
        "    best_model = None\n",
        "    best_score = -1\n",
        "\n",
        "    for model in models:\n",
        "        avg_score = filtered_df[f'{model}_score'].mean()\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_model = model\n",
        "\n",
        "    if best_model:\n",
        "        return f\"The best model for your requirements is: {best_model}, with a score of {best_score}\"\n",
        "    else:\n",
        "        return \"No suitable model found based on your preferences.\"\n",
        "\n",
        "# Main program\n",
        "def main():\n",
        "    modality, category, prompt, preferred_latency, preferred_price, preferred_accuracy = get_user_input()\n",
        "    result = suggest_best_model(modality, category, preferred_latency, preferred_price, preferred_accuracy)\n",
        "    print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDQvcZ7TDkn4",
        "outputId": "5ca84e3e-9731-4906-88f2-d2802f6859ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available modalities: ['audio' 'image' 'text' 'video']\n",
            "Enter the modality: text\n",
            "Available categories: ['content enhancement' 'content moderation' 'question answering'\n",
            " 'sentiment analysis' 'speech recognition' 'summarization' 'transcription'\n",
            " 'translation' 'voice generation' 'captioning' 'content analysis'\n",
            " 'visual description' 'text generation']\n",
            "Enter the category: text generation\n",
            "Enter your prompt: Tell me a story\n",
            "Enter your preferred maximum latency (e.g., 5): 3\n",
            "Enter your preferred maximum price (e.g., 1.5): 1\n",
            "Enter your preferred minimum accuracy (e.g., 0.6): 0.4\n",
            "The best model for your requirements is: openai/gpt-3.5-turbo-1106, with a score of 4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-983f38f6f1e6>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[f'{model}_score'] = (\n",
            "<ipython-input-14-983f38f6f1e6>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[f'{model}_score'] = (\n",
            "<ipython-input-14-983f38f6f1e6>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[f'{model}_score'] = (\n",
            "<ipython-input-14-983f38f6f1e6>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[f'{model}_score'] = (\n",
            "<ipython-input-14-983f38f6f1e6>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[f'{model}_score'] = (\n"
          ]
        }
      ]
    }
  ]
}